"""
Model definitions for Deep Twin Network replication.

The original deep twin network employs lattice models with monotonicity
constraints to learn causal mechanisms consistent with counterfactual
ordering【671066552242396†L160-L169】.  In this replication we aim to
provide an extensible base class and a simple baseline implementation
using logistic regression.  Additional strategies can be implemented
by subclassing :class:`BaseTwinModel` and overriding the
``fit`` and ``predict_proba`` methods.
"""

from __future__ import annotations

from abc import ABC, abstractmethod
from dataclasses import dataclass
from typing import Tuple, Dict, Any

import numpy as np
import pandas as pd
from sklearn.linear_model import LogisticRegression


class BaseTwinModel(ABC):
    """Abstract base class for models that predict factual and counterfactual outcomes.

    A twin model takes as input a data frame with at least the columns
    ``X``, ``U_y`` and ``X_prime`` and learns to predict the outcome
    variables ``Y`` (factual) and ``Y_prime`` (counterfactual).  Derived
    classes must implement the ``fit`` and ``predict_proba`` methods.
    """

    def __init__(self, **kwargs: Any) -> None:
        pass

    @abstractmethod
    def fit(self, X: pd.DataFrame, y: pd.DataFrame) -> 'BaseTwinModel':
        """Fit the model on training data.

        Parameters
        ----------
        X : pandas.DataFrame
            Data frame containing at least the treatment ``X`` and any
            additional covariates.  Counterfactual treatment ``X_prime``
            may be present but is not required for all strategies.
        y : pandas.DataFrame
            Data frame containing the factual outcome ``Y``.  Some
            strategies (e.g. the logistic baseline) additionally
            require a counterfactual outcome column ``Y_prime`` (used
            mainly for synthetic data).  For observational data you
            should provide only ``Y``.

        Returns
        -------
        BaseTwinModel
            Returns self to allow chaining.
        """

    @abstractmethod
    def predict_proba(self, X: pd.DataFrame) -> Tuple[np.ndarray, np.ndarray]:
        """Predict factual and counterfactual outcome probabilities.

        Parameters
        ----------
        X : pandas.DataFrame
            Data frame containing at least the treatment ``X`` and
            covariates.  Counterfactual treatment ``X_prime`` is
            optional; if absent, it will be constructed as ``1 - X``.

        Returns
        -------
        (np.ndarray, np.ndarray)
            A tuple ``(p_y, p_y_prime)`` of predicted probabilities for
            the factual and counterfactual outcomes.  Arrays have
            length ``n_samples`` and values in ``[0, 1]``.
        """


class LogisticTwinModel(BaseTwinModel):
    """Baseline twin model using logistic regression.

    This model fits two independent logistic regressions: one for the
    factual outcome ``Y`` given features ``(X, U_y)`` and one for the
    counterfactual outcome ``Y_prime`` given ``(X_prime, U_y)``.

    Although this differs from the lattice architecture in the
    original paper, it preserves the core idea of estimating
    probabilities for both factual and counterfactual outcomes based
    on the same latent information.  It also demonstrates how to use
    the strategy pattern: other models can be implemented by
    subclassing :class:`BaseTwinModel` and replacing the two logistic
    regressions with alternative estimators.
    """

    def __init__(self, **kwargs: Any) -> None:
        super().__init__(**kwargs)
        # separate models for Y and Y'
        self.model_y = LogisticRegression(max_iter=500)
        self.model_y_prime = LogisticRegression(max_iter=500)

    def fit(self, X: pd.DataFrame, y: pd.DataFrame) -> 'LogisticTwinModel':
        """
        Fit two logistic regressions on synthetic data.

        This strategy requires both the factual outcome ``Y`` and the
        counterfactual outcome ``Y_prime`` in ``y``.  It is intended
        primarily for the synthetic dataset where both outcomes are
        generated by design.  For observational data, consider using
        SLearner or TLearner strategies instead.
        """
        if 'Y_prime' not in y.columns:
            raise ValueError(
                "LogisticTwinModel requires both 'Y' and 'Y_prime' in the target dataframe. "
                "For observational data use SLearnerTwinModel or TLearnerTwinModel.")
        # prepare feature matrices for factual and counterfactual treatments
        if 'U_y' not in X.columns:
            raise ValueError("Column 'U_y' must be present in X for LogisticTwinModel.")
        X_factual = X[['X', 'U_y']].to_numpy()
        # fall back to constructing X_prime if missing
        X_prime_col = 'X_prime' if 'X_prime' in X.columns else None
        if X_prime_col is None:
            X_prime = 1 - X['X']
            X_counter = np.stack([X_prime.to_numpy(), X['U_y'].to_numpy()], axis=1)
        else:
            X_counter = X[[X_prime_col, 'U_y']].to_numpy()
        # extract targets
        y_factual = y['Y'].astype(int).to_numpy()
        y_counter = y['Y_prime'].astype(int).to_numpy()
        # fit logistic models
        self.model_y.fit(X_factual, y_factual)
        self.model_y_prime.fit(X_counter, y_counter)
        return self

    def predict_proba(self, X: pd.DataFrame) -> Tuple[np.ndarray, np.ndarray]:
        # compute features for factual outcome
        if 'U_y' not in X.columns:
            raise ValueError("Column 'U_y' must be present in X for LogisticTwinModel predictions.")
        X_factual = X[['X', 'U_y']].to_numpy()
        # compute counterfactual treatment
        if 'X_prime' in X.columns:
            X_counter = X[['X_prime', 'U_y']].to_numpy()
        else:
            X_counter = np.stack([(1 - X['X']).to_numpy(), X['U_y'].to_numpy()], axis=1)
        p_y = self.model_y.predict_proba(X_factual)[:, 1]
        p_y_prime = self.model_y_prime.predict_proba(X_counter)[:, 1]
        return p_y, p_y_prime


class SLearnerTwinModel(BaseTwinModel):
    """S‑learner strategy for potential outcome estimation.

    A single machine‐learning model is trained using the treatment
    variable ``X`` as an input feature along with optional covariates.
    To obtain potential outcomes, we feed the trained model two
    versions of each instance: one with treatment ``X=1`` and one
    with treatment ``X=0``.  The predicted probabilities from these
    two passes yield estimated P(Y=1|do(X=1), Z) and
    P(Y=1|do(X=0), Z).  This approach requires only the factual
    outcome ``Y`` for training and is suitable for observational data.
    """

    def __init__(self, base_estimator: Any | None = None, **kwargs: Any) -> None:
        super().__init__(**kwargs)
        from sklearn.ensemble import GradientBoostingClassifier
        # use a gradient boosting classifier by default
        self.model = base_estimator or GradientBoostingClassifier()

    def fit(self, X: pd.DataFrame, y: pd.DataFrame) -> 'SLearnerTwinModel':
        if 'Y' not in y.columns:
            raise ValueError("SLearnerTwinModel requires column 'Y' in target dataframe.")
        # build feature matrix including treatment
        # include all columns except any counterfactual ones
        feature_cols = [col for col in X.columns if col != 'X_prime']
        X_mat = X[feature_cols].to_numpy()
        y_vec = y['Y'].astype(int).to_numpy()
        self.model.fit(X_mat, y_vec)
        self.feature_cols = feature_cols
        return self

    def predict_proba(self, X: pd.DataFrame) -> Tuple[np.ndarray, np.ndarray]:
        # ensure model is fitted
        # prepare feature matrix for factual treatment
        if not hasattr(self, 'feature_cols'):
            raise RuntimeError("Model not fitted. Call fit() first.")
        # features excluding any X_prime column
        X_copy = X.copy()
        # compute factual and counterfactual probabilities by toggling treatment
        # actual treatment features
        features_factual = X_copy[self.feature_cols].to_numpy()
        # compute counterfactual features: set X=1-X
        cf_df = X_copy.copy()
        if 'X' in cf_df.columns:
            cf_df['X'] = 1 - cf_df['X']
        features_counter = cf_df[self.feature_cols].to_numpy()
        p_y = self.model.predict_proba(features_factual)[:, 1]
        p_y_prime = self.model.predict_proba(features_counter)[:, 1]
        return p_y, p_y_prime


class TLearnerTwinModel(BaseTwinModel):
    """T‑learner strategy for potential outcome estimation.

    Two separate models are trained: one on treated units and one on
    control units.  At prediction time each model is used to generate
    potential outcomes for all units.  As with S‑learner, only the
    factual outcome ``Y`` is required for training.  This approach
    naturally handles heterogeneity between treated and control
    subpopulations but may be less data efficient when treatment
    groups are imbalanced.
    """

    def __init__(self, base_estimator: Any | None = None, **kwargs: Any) -> None:
        super().__init__(**kwargs)
        from sklearn.ensemble import RandomForestClassifier
        # default base learner
        self.model_treated = base_estimator or RandomForestClassifier(max_depth=5, n_estimators=100)
        self.model_control = base_estimator or RandomForestClassifier(max_depth=5, n_estimators=100)

    def fit(self, X: pd.DataFrame, y: pd.DataFrame) -> 'TLearnerTwinModel':
        if 'Y' not in y.columns:
            raise ValueError("TLearnerTwinModel requires column 'Y' in target dataframe.")
        if 'X' not in X.columns:
            raise ValueError("TLearnerTwinModel requires treatment column 'X' in feature dataframe.")
        # select features excluding treatment and counterfactual columns
        feature_cols = [col for col in X.columns if col not in ('X', 'X_prime')]
        # treated subset
        treated_mask = X['X'] == 1
        X_treated = X.loc[treated_mask, feature_cols]
        y_treated = y.loc[treated_mask, 'Y'].astype(int)
        # control subset
        control_mask = X['X'] == 0
        X_control = X.loc[control_mask, feature_cols]
        y_control = y.loc[control_mask, 'Y'].astype(int)
        # fit models
        self.model_treated.fit(X_treated.to_numpy(), y_treated.to_numpy())
        self.model_control.fit(X_control.to_numpy(), y_control.to_numpy())
        self.feature_cols = feature_cols
        return self

    def predict_proba(self, X: pd.DataFrame) -> Tuple[np.ndarray, np.ndarray]:
        if not hasattr(self, 'feature_cols'):
            raise RuntimeError("Model not fitted. Call fit() first.")
        # features excluding treatment and X_prime
        features = X[self.feature_cols].to_numpy()
        # predictions for treated (Y1) and control (Y0) for all units
        p_y1 = self.model_treated.predict_proba(features)[:, 1]
        p_y0 = self.model_control.predict_proba(features)[:, 1]
        # factual probabilities correspond to actual treatment
        if 'X' in X.columns:
            p_factual = np.where(X['X'] == 1, p_y1, p_y0)
        else:
            p_factual = p_y1  # fallback
        # counterfactual probabilities correspond to opposite treatment
        p_counter = np.where(X.get('X', 1 - X.get('X', 0)) == 1, p_y0, p_y1)
        return p_factual, p_counter


class XLearnerTwinModel(BaseTwinModel):
    """X‑learner strategy for heterogeneous treatment effect estimation.

    The X‑learner is a meta‑learning approach that aims to reduce
    variance in treatment effect estimation by modelling the effect
    directly.  It proceeds in four steps:

    1.  Fit outcome models for the treated and control groups
        separately (as in the T‑learner) to obtain predicted
        potential outcomes ``m_t`` and ``m_c``.
    2.  Compute imputed treatment effects for each unit: for
        treated units (``X=1``) the effect is ``Y - m_c(features)``;
        for control units (``X=0``) it is ``m_t(features) - Y``.
    3.  Fit effect models on the treated and control groups using
        regressors (not classifiers) to predict the imputed effect
        from the features.
    4.  At prediction time, estimate the treatment effect for a new
        observation as a weighted combination of the treated and
        control effect model predictions.  The predicted potential
        outcomes are then ``Y0_hat = m_c(x)`` and
        ``Y1_hat = m_c(x) + tau_hat``.  Predictions are clipped
        to the interval ``[0, 1]``.

    This implementation assumes binary outcomes and treatments.  It
    requires only the factual outcome ``Y`` for training and can
    accommodate observational data where counterfactual labels are
    unavailable.
    """

    def __init__(self,
                 outcome_model: Any | None = None,
                 effect_model: Any | None = None,
                 **kwargs: Any) -> None:
        super().__init__(**kwargs)
        from sklearn.ensemble import GradientBoostingClassifier, GradientBoostingRegressor
        # Base learners for the outcome models (classification)
        self.model_treated = outcome_model or GradientBoostingClassifier()
        self.model_control = outcome_model or GradientBoostingClassifier()
        # Regressors for the effect models (continuous effect)
        self.effect_model_treated = effect_model or GradientBoostingRegressor()
        self.effect_model_control = effect_model or GradientBoostingRegressor()

    def fit(self, X: pd.DataFrame, y: pd.DataFrame) -> 'XLearnerTwinModel':
        if 'Y' not in y.columns:
            raise ValueError("XLearnerTwinModel requires column 'Y' in target dataframe.")
        if 'X' not in X.columns:
            raise ValueError("XLearnerTwinModel requires treatment column 'X' in feature dataframe.")
        # select feature columns excluding treatment and any counterfactual columns
        self.feature_cols = [col for col in X.columns if col not in ('X', 'X_prime')]
        features = X[self.feature_cols].to_numpy()
        treatment = X['X'].to_numpy()
        target = y['Y'].astype(int).to_numpy()
        # split into treated and control indices
        treated_idx = np.where(treatment == 1)[0]
        control_idx = np.where(treatment == 0)[0]
        X_treated = features[treated_idx]
        y_treated = target[treated_idx]
        X_control = features[control_idx]
        y_control = target[control_idx]
        # fit outcome models on treated and control
        self.model_treated.fit(X_treated, y_treated)
        self.model_control.fit(X_control, y_control)
        # compute imputed treatment effects
        # for treated: effect = y_i - m_c(x_i)
        m_c_on_treated = self.model_control.predict_proba(X_treated)[:, 1]
        effect_treated = y_treated - m_c_on_treated
        # for control: effect = m_t(x_j) - y_j
        m_t_on_control = self.model_treated.predict_proba(X_control)[:, 1]
        effect_control = m_t_on_control - y_control
        # fit effect models
        self.effect_model_treated.fit(X_treated, effect_treated)
        self.effect_model_control.fit(X_control, effect_control)
        # compute treatment propensity (weight) as fraction of treated in the data
        self.propensity = float(len(treated_idx)) / max(len(treated_idx) + len(control_idx), 1)
        return self

    def predict_proba(self, X: pd.DataFrame) -> Tuple[np.ndarray, np.ndarray]:
        if not hasattr(self, 'feature_cols'):
            raise RuntimeError("Model not fitted. Call fit() first.")
        features = X[self.feature_cols].to_numpy()
        # predicted outcomes from outcome models
        m_t = self.model_treated.predict_proba(features)[:, 1]
        m_c = self.model_control.predict_proba(features)[:, 1]
        # predicted treatment effects from effect models
        tau_t = self.effect_model_treated.predict(features)
        tau_c = self.effect_model_control.predict(features)
        # combine effects using propensity weight
        w = self.propensity
        tau_hat = w * tau_c + (1.0 - w) * tau_t
        # predicted potential outcomes
        y0_hat = m_c
        y1_hat = np.clip(m_c + tau_hat, 0.0, 1.0)
        # assign factual and counterfactual based on actual treatment
        if 'X' in X.columns:
            treatment = X['X'].to_numpy()
            p_factual = np.where(treatment == 1, y1_hat, y0_hat)
            p_counter = np.where(treatment == 1, y0_hat, y1_hat)
        else:
            p_factual = y1_hat  # if treatment missing assume treated
            p_counter = y0_hat
        return p_factual, p_counter
